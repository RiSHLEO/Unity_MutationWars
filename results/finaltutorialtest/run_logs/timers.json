{
    "name": "root",
    "gauges": {
        "Agent.Policy.Entropy.mean": {
            "value": 1.348889946937561,
            "min": 1.348889946937561,
            "max": 1.417888879776001,
            "count": 20
        },
        "Agent.Policy.Entropy.sum": {
            "value": 67328.4921875,
            "min": 67286.03125,
            "max": 72023.0859375,
            "count": 20
        },
        "Agent.Step.mean": {
            "value": 999948.0,
            "min": 49967.0,
            "max": 999948.0,
            "count": 20
        },
        "Agent.Step.sum": {
            "value": 999948.0,
            "min": 49967.0,
            "max": 999948.0,
            "count": 20
        },
        "Agent.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.6015538573265076,
            "min": -0.20199815928936005,
            "max": 0.6015538573265076,
            "count": 20
        },
        "Agent.Policy.ExtrinsicValueEstimate.sum": {
            "value": 542.0,
            "min": -162.6085205078125,
            "max": 542.0,
            "count": 20
        },
        "Agent.Environment.EpisodeLength.mean": {
            "value": 238.44394618834082,
            "min": 238.44394618834082,
            "max": 1411.111111111111,
            "count": 20
        },
        "Agent.Environment.EpisodeLength.sum": {
            "value": 53173.0,
            "min": 38100.0,
            "max": 54923.0,
            "count": 20
        },
        "Agent.Environment.CumulativeReward.mean": {
            "value": 2.021456574042012,
            "min": -3.2428564277425824,
            "max": 2.021456574042012,
            "count": 20
        },
        "Agent.Environment.CumulativeReward.sum": {
            "value": 452.8062725854106,
            "min": -87.55712354904972,
            "max": 452.8062725854106,
            "count": 20
        },
        "Agent.Policy.ExtrinsicReward.mean": {
            "value": 2.021456574042012,
            "min": -3.2428564277425824,
            "max": 2.021456574042012,
            "count": 20
        },
        "Agent.Policy.ExtrinsicReward.sum": {
            "value": 452.8062725854106,
            "min": -87.55712354904972,
            "max": 452.8062725854106,
            "count": 20
        },
        "Agent.Losses.PolicyLoss.mean": {
            "value": 0.03542754917095105,
            "min": 0.032368951433648666,
            "max": 0.03747621082972425,
            "count": 20
        },
        "Agent.Losses.PolicyLoss.sum": {
            "value": 0.17713774585475525,
            "min": 0.1328775147868631,
            "max": 0.1855872425988006,
            "count": 20
        },
        "Agent.Losses.ValueLoss.mean": {
            "value": 0.09326932147145271,
            "min": 0.018239546541978294,
            "max": 0.09326932147145271,
            "count": 20
        },
        "Agent.Losses.ValueLoss.sum": {
            "value": 0.4663466073572636,
            "min": 0.07295818616791318,
            "max": 0.4663466073572636,
            "count": 20
        },
        "Agent.Policy.LearningRate.mean": {
            "value": 6.744937751719999e-06,
            "min": 6.744937751719999e-06,
            "max": 0.00029223555258814994,
            "count": 20
        },
        "Agent.Policy.LearningRate.sum": {
            "value": 3.37246887586e-05,
            "min": 3.37246887586e-05,
            "max": 0.0013908507363830998,
            "count": 20
        },
        "Agent.Policy.Epsilon.mean": {
            "value": 0.10224828,
            "min": 0.10224828,
            "max": 0.19741184999999997,
            "count": 20
        },
        "Agent.Policy.Epsilon.sum": {
            "value": 0.5112414,
            "min": 0.5097333000000001,
            "max": 0.9636168999999999,
            "count": 20
        },
        "Agent.Policy.Beta.mean": {
            "value": 0.00012218917200000002,
            "min": 0.00012218917200000002,
            "max": 0.004870851315,
            "count": 20
        },
        "Agent.Policy.Beta.sum": {
            "value": 0.0006109458600000001,
            "min": 0.0006109458600000001,
            "max": 0.023184483309999997,
            "count": 20
        },
        "Agent.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 20
        },
        "Agent.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 20
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1753148172",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\risha\\miniconda3\\envs\\mlagents\\Scripts\\mlagents-learn config/Turtle.yaml --run-id=finaltutorialtest --force",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.2.2+cu121",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1753148849"
    },
    "total": 677.3383190000895,
    "count": 1,
    "self": 0.005706800147891045,
    "children": {
        "run_training.setup": {
            "total": 0.07141149998642504,
            "count": 1,
            "self": 0.07141149998642504
        },
        "TrainerController.start_learning": {
            "total": 677.2612006999552,
            "count": 1,
            "self": 0.600829008850269,
            "children": {
                "TrainerController._reset_env": {
                    "total": 17.75794549996499,
                    "count": 1,
                    "self": 17.75794549996499
                },
                "TrainerController.advance": {
                    "total": 658.8557409910718,
                    "count": 57038,
                    "self": 0.5969025042140856,
                    "children": {
                        "env_step": {
                            "total": 445.80702218809165,
                            "count": 57038,
                            "self": 332.43711339484435,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 112.93956679583061,
                                    "count": 57038,
                                    "self": 2.077885602018796,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 110.86168119381182,
                                            "count": 55582,
                                            "self": 110.86168119381182
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.43034199741669,
                                    "count": 57038,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 659.132368593011,
                                            "count": 57038,
                                            "is_parallel": true,
                                            "self": 381.54117559688166,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0006766000296920538,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00039110006764531136,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00028549996204674244,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.00028549996204674244
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 277.5905163960997,
                                                    "count": 57038,
                                                    "is_parallel": true,
                                                    "self": 6.901335689122789,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 9.386953198583797,
                                                            "count": 57038,
                                                            "is_parallel": true,
                                                            "self": 9.386953198583797
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 245.94375020859297,
                                                            "count": 57038,
                                                            "is_parallel": true,
                                                            "self": 245.94375020859297
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 15.358477299800143,
                                                            "count": 57038,
                                                            "is_parallel": true,
                                                            "self": 3.829164594062604,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 11.529312705737539,
                                                                    "count": 228152,
                                                                    "is_parallel": true,
                                                                    "self": 11.529312705737539
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 212.45181629876606,
                            "count": 57038,
                            "self": 0.941996406763792,
                            "children": {
                                "process_trajectory": {
                                    "total": 69.96414159110282,
                                    "count": 57038,
                                    "self": 69.86522119108122,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.09892040002159774,
                                            "count": 2,
                                            "self": 0.09892040002159774
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 141.54567830089945,
                                    "count": 97,
                                    "self": 90.72245419886895,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 50.82322410203051,
                                            "count": 5820,
                                            "self": 50.82322410203051
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 7.00005330145359e-07,
                    "count": 1,
                    "self": 7.00005330145359e-07
                },
                "TrainerController._save_models": {
                    "total": 0.0466845000628382,
                    "count": 1,
                    "self": 0.010217400034889579,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.03646710002794862,
                            "count": 1,
                            "self": 0.03646710002794862
                        }
                    }
                }
            }
        }
    }
}